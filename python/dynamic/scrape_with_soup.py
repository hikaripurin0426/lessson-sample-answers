#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã€å¤±æ•—ä¾‹ã€‘BeautifulSoupã§å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã‚ˆã†ã¨ã™ã‚‹
ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ„å›³çš„ã«å¤±æ•—ã—ã¾ã™ï¼š
- JavaScriptã§ç”Ÿæˆã•ã‚Œã‚‹è¦ç´ ã¯å–å¾—ã§ãã¾ã›ã‚“
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã•ã‚Œã‚‹è¦ç´ ã¯å¤ã„å€¤ã—ã‹å–å¾—ã§ãã¾ã›ã‚“
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ãªè¦ç´ ã¯å–å¾—ã§ãã¾ã›ã‚“

Seleniumã¨ã®é•ã„ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®æ•™æã¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
"""

import requests
from bs4 import BeautifulSoup

def scrape_dynamic_page_with_soup():
    """BeautifulSoupã§å‹•çš„ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆå¤±æ•—ä¾‹ï¼‰"""
    print("ğŸŒ BeautifulSoupã§å‹•çš„ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
    
    url = "https://scraping-practice-six.vercel.app/dynamic"
    
    try:
        # é€šå¸¸ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = requests.get(url)
        response.raise_for_status()
        print("âœ“ ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ")
        
        # BeautifulSoupã§è§£æ
        soup = BeautifulSoup(response.content, 'html.parser')
        print("âœ“ HTMLè§£æå®Œäº†")
        
    except Exception as e:
        print(f"âœ— ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: {e}")
        return

    print("\n" + "=" * 60)
    print("BeautifulSoupã§ã®å–å¾—çµæœï¼ˆå¤±æ•—ä¾‹ï¼‰")
    print("=" * 60)

    # 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ™‚åˆ»ã®å–å¾—ã‚’è©¦è¡Œ
    print("\n1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ™‚åˆ»å–å¾—ã‚’è©¦è¡Œ...")
    try:
        time_element = soup.find('div', id='current-time')
        if time_element:
            print(f"  å–å¾—ã—ãŸæ™‚åˆ»: {time_element.get_text(strip=True)}")
            print("  âš ï¸  ã“ã®æ™‚åˆ»ã¯é™çš„ãªHTMLã®åˆæœŸå€¤ã§ã™")
            print("  âš ï¸  å®Ÿéš›ã®ç¾åœ¨æ™‚åˆ»ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        else:
            print("  âœ— æ™‚åˆ»è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("  â†’ JavaScriptã§å‹•çš„ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")

    # 2. ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤ã®å–å¾—ã‚’è©¦è¡Œ
    print("\n2. ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤å–å¾—ã‚’è©¦è¡Œ...")
    try:
        counter_element = soup.find('div', id='counter-value')
        if counter_element:
            counter_value = counter_element.get_text(strip=True)
            data_count = counter_element.get('data-count', 'ãªã—')
            print(f"  å–å¾—ã—ãŸã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤: {counter_value}")
            print(f"  data-countå±æ€§: {data_count}")
            print("  âš ï¸  ã“ã‚Œã¯åˆæœŸå€¤ï¼ˆ0ï¼‰ã®ã¿ã§ã™")
            print("  âš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå¾Œã®å€¤ã¯å–å¾—ã§ãã¾ã›ã‚“")
        else:
            print("  âœ— ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")

    # 3. å‹•çš„ãƒªã‚¹ãƒˆã®å–å¾—ã‚’è©¦è¡Œ
    print("\n3. å‹•çš„ãƒªã‚¹ãƒˆå–å¾—ã‚’è©¦è¡Œ...")
    try:
        list_items = soup.find_all('li', class_='dynamic-item')
        print(f"  å–å¾—ã—ãŸãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ æ•°: {len(list_items)}å€‹")
        
        if list_items:
            for i, item in enumerate(list_items):
                item_text_elem = item.find('span', class_='item-text')
                if item_text_elem:
                    print(f"    ã‚¢ã‚¤ãƒ†ãƒ {i+1}: {item_text_elem.get_text(strip=True)}")
            print("  âš ï¸  ã“ã‚Œã¯åˆæœŸã‚¢ã‚¤ãƒ†ãƒ ã®ã¿ã§ã™")
            print("  âš ï¸  ã€Œã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ ã€ãƒœã‚¿ãƒ³ã§è¿½åŠ ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ ã¯è¦‹ãˆã¾ã›ã‚“")
        else:
            print("  âš ï¸  å‹•çš„ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("  â†’ JavaScriptã§å‹•çš„ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")

    # 4. éåŒæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å–å¾—ã‚’è©¦è¡Œ
    print("\n4. éåŒæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚’è©¦è¡Œ...")
    try:
        news_items = soup.find_all('article', class_='news-item')
        print(f"  å–å¾—ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {len(news_items)}å€‹")
        
        if len(news_items) > 0:
            for i, news in enumerate(news_items):
                title_elem = news.find('h3', class_='news-title')
                if title_elem:
                    print(f"    ãƒ‹ãƒ¥ãƒ¼ã‚¹{i+1}: {title_elem.get_text(strip=True)}")
            print("  âš ï¸  åˆæœŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            print("  â†’ ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿æ™‚ã«JavaScriptã§éåŒæœŸãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™")
        else:
            print("  âœ— ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("  â†’ 2ç§’ã®éåŒæœŸèª­ã¿è¾¼ã¿å¾…æ©ŸãŒå¿…è¦ã§ã™")
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")

    # 5. æ¡ä»¶ä»˜ãè¡¨ç¤ºè¦ç´ ã®å–å¾—ã‚’è©¦è¡Œ
    print("\n5. æ¡ä»¶ä»˜ãè¡¨ç¤ºè¦ç´ å–å¾—ã‚’è©¦è¡Œ...")
    try:
        conditional_element = soup.find('div', id='conditional-message')
        if conditional_element:
            style = conditional_element.get('style', '')
            data_visible = conditional_element.get('data-visible', 'ãªã—')
            print(f"  è¦ç´ ã®å­˜åœ¨: ç¢ºèª")
            print(f"  styleå±æ€§: {style}")
            print(f"  data-visibleå±æ€§: {data_visible}")
            print("  âš ï¸  åˆæœŸçŠ¶æ…‹ï¼ˆéè¡¨ç¤ºï¼‰ã®æƒ…å ±ã®ã¿å–å¾—å¯èƒ½")
            print("  âš ï¸  ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æ“ä½œå¾Œã®çŠ¶æ…‹å¤‰åŒ–ã¯è¿½è·¡ã§ãã¾ã›ã‚“")
        else:
            print("  âœ— æ¡ä»¶ä»˜ãè¡¨ç¤ºè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")


    print("\n" + "=" * 60)
    print("çµè«–: BeautifulSoupã®é™ç•Œ")
    print("=" * 60)
    print("âŒ JavaScriptç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ â†’ å–å¾—ä¸å¯")
    print("âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–° â†’ å–å¾—ä¸å¯") 
    print("âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ â†’ å®Ÿè¡Œä¸å¯")
    print("âŒ éåŒæœŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â†’ å¾…æ©Ÿä¸å¯")
    print("âŒ å‹•çš„ãªçŠ¶æ…‹å¤‰åŒ– â†’ è¿½è·¡ä¸å¯")
    print()
    print("âœ… è§£æ±ºç­–: Seleniumã‚’ä½¿ç”¨")
    print("  â†’ ãƒ–ãƒ©ã‚¦ã‚¶ã‚¨ãƒ³ã‚¸ãƒ³ã§JavaScriptå®Ÿè¡Œ")
    print("  â†’ å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ")
    print("  â†’ å‹•çš„ãªå¤‰åŒ–ã‚’å¾…æ©Ÿãƒ»ç›£è¦–")
    print("=" * 60)

if __name__ == "__main__":
    print("ğŸš« å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é™çš„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆå¤±æ•—ä¾‹ï¼‰")
    print("=" * 60)
    scrape_dynamic_page_with_soup()
